{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592b85ed-0a4b-4d85-a88f-756ed4964f11",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network (GCN) Pipeline for ENZYMES Dataset\n",
    "\n",
    "**Author:** Shuai Huang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d66de1-e9a0-4bea-a313-974453af8f27",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff5620-6d07-4178-b87c-dfe751d873ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "This assignment focuses on implementing Graph Convolutional Networks (GCNs) for graph classification using the ENZYMES dataset from PyTorch Geometric. You will explore graph structures, preprocess the data, implement GCN models (both manually and using PyG), and evaluate their performance.\n",
    "\n",
    "Please fill in the missing code between the designated markers:\n",
    "\n",
    "    ```Python\n",
    "    ### Your code starts\n",
    "    ```\n",
    "    and\n",
    "    ```Python\n",
    "    ### Your code ends\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6852e4f-27d5-4366-bd5d-e6ff88647f90",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ec83d-7929-4e27-80b1-185ca638513d",
   "metadata": {},
   "source": [
    "### ENZYMES Dataset Overview\n",
    "\n",
    "The **ENZYMES dataset** is a collection of **600 graphs**, where each graph represents a **protein**.  \n",
    "The **nodes** in each graph correspond to **amino acids (residues)**, and **edges** represent **spatial closeness** between residues.  \n",
    "The dataset is used for **graph classification**, where the goal is to predict the **enzyme class** of each protein.  \n",
    "There are **six enzyme classes** in total.\n",
    "\n",
    "#### **Graph Structure**\n",
    "Each graph has:\n",
    "\n",
    "- **Nodes**: Amino acids (**average ~32 nodes per graph**)\n",
    "- **Edges**: Spatial connectivity (**~62 edges per graph**)\n",
    "- **Node Features**: **21-dimensional feature vectors per node**\n",
    "- **Graph Labels**: One of **six enzyme classes**\n",
    "\n",
    "#### **Use Cases**\n",
    "This dataset is widely used in **biochemical function prediction** and is suitable for training **Graph Neural Networks (GNNs)** such as **Graph Convolutional Networks (GCN)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd16a4-791a-4bcf-b69b-899a70d54080",
   "metadata": {},
   "source": [
    "## 1. Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc9525-9232-401e-85c5-c7bbd4670056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad00c7-01bc-47da-b9ec-bae1d34e4fec",
   "metadata": {},
   "source": [
    "## 2. Package Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b64d9b-958e-45a6-9e8f-bd739e501f84",
   "metadata": {},
   "source": [
    "To use PyTorch Geometric (PyG), we need to install PyTorch, torch_geometric, and the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c62bb1-9081-4d52-b007-7adad63f8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (if not installed)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install PyTorch Geometric dependencies\n",
    "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd299e5-ed92-4c78-9dd6-1b5cee5c471c",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266f2de-8d2c-4a36-b3fe-967d1b929017",
   "metadata": {},
   "source": [
    "We will download the ENZYMES dataset using TUDataset from PyTorch Geometric and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477d277-cb5e-4786-9cc2-b806c413305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Load the ENZYMES dataset\n",
    "dataset = TUDataset(root='data/ENZYMES', name='ENZYMES')\n",
    "\n",
    "# Move the dataset to the selected device (CPU/GPU)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "print(f\"Dataset loaded: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Node feature dimension: {dataset.num_node_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e64fe-ed07-4e16-ad60-578e3b2382c3",
   "metadata": {},
   "source": [
    "## 4. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93349004-9a5f-4736-bc36-78cafd733e8f",
   "metadata": {},
   "source": [
    "### Instruction:\n",
    "Before training, we should explore the dataset to understand its structure:\n",
    "\n",
    "- **Total number of graphs**\n",
    "- **Number of nodes per graph**\n",
    "- **Number of edges per graph**\n",
    "- **Node features and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7b473-2081-4aac-9641-5e02c021d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get basic dataset statistics\n",
    "### Your code starts\n",
    "num_graphs = \n",
    "num_classes = \n",
    "num_node_features = \n",
    "### Your code ends\n",
    "\n",
    "# Collect statistics about node and edge counts\n",
    "num_nodes_list = []\n",
    "num_edges_list = []\n",
    "\n",
    "for graph in dataset:\n",
    "    num_nodes_list.append(graph.num_nodes)\n",
    "    num_edges_list.append(graph.num_edges)\n",
    "\n",
    "print(f\"Total Graphs: {num_graphs}\")\n",
    "print(f\"Number of Classes: {num_classes}\")\n",
    "print(f\"Node Feature Dimension: {num_node_features}\")\n",
    "\n",
    "print(f\"Avg. Nodes per Graph: {np.mean(num_nodes_list):.2f}\")\n",
    "print(f\"Avg. Edges per Graph: {np.mean(num_edges_list):.2f}\")\n",
    "\n",
    "# Visualize the first graph\n",
    "first_graph = dataset[0]\n",
    "print(f\"First Graph Details:\\n {first_graph}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb413c2-3384-4f20-b935-3eafa4f6fc1a",
   "metadata": {},
   "source": [
    "## 5. Preprocessing (Normalization, Splitting into Train/Validation/Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61f5c5-5601-4948-b1af-64fdb4f39197",
   "metadata": {},
   "source": [
    "### Instruction:\n",
    "- Shuffle the dataset before splitting.\n",
    "- Normalize node features to ensure better convergence.\n",
    "- Split the dataset into train (80%), validation (10%), and test (10%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18933c50-d776-4a09-8e6e-255d894f56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Normalize the node features\n",
    "### Your code starts\n",
    "dataset = TUDataset(root=\"data/ENZYMES\", name=\"ENZYMES\", transform=NormalizeFeatures())\n",
    "\n",
    "\n",
    "### Your code ends\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f8db3-820f-4ab9-ad5a-3c3020a259df",
   "metadata": {},
   "source": [
    "## 6. GCN Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff6539-7659-40a6-b10a-79e3cc4cd12d",
   "metadata": {},
   "source": [
    "Instruction:\n",
    "We will implement two GCN models:\n",
    "\n",
    "1. GCN by hand (using basic matrix operations)\n",
    "2. GCN using PyG (utilizing torch_geometric.nn.GCNConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c540c-9605-40cf-9d2b-f401cd74927f",
   "metadata": {},
   "source": [
    "### 6.1 Implementing GCN by Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0939436-34d6-4103-a523-c543e62e82c7",
   "metadata": {},
   "source": [
    "We will manually implement the **graph convolution operation** **without** using `torch_geometric.nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115b83f-d65e-4f1e-9832-5f5cea4585a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import global_mean_pool  # For graph-level pooling\n",
    "\n",
    "class GCNHandmade(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNHandmade, self).__init__()\n",
    "        ### Your code starts\n",
    "        self.fc1 = \n",
    "        self.fc2 = \n",
    "        self.classifier =   # Final graph-level classification layer\n",
    "        ### Your code ends\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        ### Your code starts\n",
    "\n",
    "        # Step 1: Add self-loops\n",
    "        \n",
    "\n",
    "        # Step 2: Compute degree matrix\n",
    "        \n",
    "\n",
    "        # Step 3: Normalize adjacency matrix\n",
    "        \n",
    "\n",
    "        # Step 4: Message Passing\n",
    "        \n",
    "\n",
    "        # Step 5: **Graph-level pooling** (Aggregate node representations into a single vector per graph)\n",
    "        \n",
    "\n",
    "        # Step 6: Final classification\n",
    "        \n",
    "        \n",
    "        ### Your code ends\n",
    "\n",
    "        return F.log_softmax(out, dim=1)  # Graph-level classification output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635dca1-b073-482a-a85c-928b9f9c7e7f",
   "metadata": {},
   "source": [
    "## 6.2 Implementing GCN using PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b1c64-2f05-4a4b-bed2-24d21de7f565",
   "metadata": {},
   "source": [
    "Now, we define a GCN model using PyG's built-in layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e4f36-050b-43d5-bf09-14006c06b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GCNPyG(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNPyG, self).__init__()\n",
    "        ### Your code starts\n",
    "        self.conv1 = \n",
    "        self.conv2 = \n",
    "        self.classifier =   # Graph-level classifier\n",
    "        ### Your code ends\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        ### Your code starts\n",
    "        \n",
    "        # Step 1: apply GCN layers with activation functions\n",
    "        \n",
    "\n",
    "        # Step 2: Graph-level pooling (aggregate node embeddings per graph)\n",
    "        \n",
    "        \n",
    "        ### Your code ends\n",
    "        \n",
    "        # Final graph-level classification\n",
    "        out = self.classifier(x_graph)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b813d60-7908-4716-8776-4ac107b0be38",
   "metadata": {},
   "source": [
    "## 7. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf6d62-46e2-400d-a869-8ef2c9b1108c",
   "metadata": {},
   "source": [
    "We will train both models using the same pipeline and store hyperparameters in a dictionary for easy tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e826ac-3c13-451f-b08b-ccf5b8a38437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "hyperparams = {\n",
    "    \"hidden_channels\": 64,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "# Define loss function and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, train_dataset, val_dataset):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"learning_rate\"])\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(hyperparams[\"epochs\"]):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for graph in train_dataset:\n",
    "            graph = graph.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(graph.x, graph.edge_index, graph.batch)  # Pass batch indices\n",
    "            loss = loss_fn(out, graph.y)  # Graph-level loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "    print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273e8e6-4148-4f3d-868b-c5f4fb10bb31",
   "metadata": {},
   "source": [
    "## 8. Evaluating the Model\n",
    "\n",
    "We will evaluate both models and plot accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2e329-3b47-4a45-bf7b-fc7ff451654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for graph in test_dataset:\n",
    "            graph = graph.to(device)\n",
    "\n",
    "            out = model(graph.x, graph.edge_index, graph.batch)  # **Pass batch index**\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == graph.y).sum().item()\n",
    "            total += graph.y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate both models\n",
    "gcn_handmade = GCNHandmade(dataset.num_node_features, hyperparams[\"hidden_channels\"], dataset.num_classes)\n",
    "gcn_pyg = GCNPyG(dataset.num_node_features, hyperparams[\"hidden_channels\"], dataset.num_classes)\n",
    "\n",
    "print(\"\\nTraining GCN (Handmade)...\")\n",
    "train(gcn_handmade, train_dataset, val_dataset)\n",
    "\n",
    "print(\"\\nTraining GCN (PyG)...\")\n",
    "train(gcn_pyg, train_dataset, val_dataset)\n",
    "\n",
    "# Evaluate both models\n",
    "acc_handmade = evaluate(gcn_handmade, test_dataset)\n",
    "acc_pyg = evaluate(gcn_pyg, test_dataset)\n",
    "\n",
    "# Plot results\n",
    "models = [\"GCN Handmade\", \"GCN PyG\"]\n",
    "accuracies = [acc_handmade, acc_pyg]\n",
    "\n",
    "plt.bar(models, accuracies, color=['blue', 'green'])\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Comparison of GCN Implementations\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a24dd-ea66-4a95-b803-8c2e08c46dfc",
   "metadata": {},
   "source": [
    "## 9. Making Predictions\n",
    "\n",
    "We will make predictions on test samples and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ac03f-0969-45e8-b461-38ef6ba790b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "def make_predictions_and_plot(model, test_dataset):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for graph in test_dataset:\n",
    "            graph = graph.to(device)\n",
    "            out = model(graph.x, graph.edge_index, graph.batch)  # Pass batch index\n",
    "            prob = torch.exp(out)  # Convert log-softmax to probabilities\n",
    "            pred = prob.argmax(dim=1)\n",
    "\n",
    "            all_preds.append(pred.item())\n",
    "            all_labels.append(graph.y.item())\n",
    "            all_probs.append(prob[:, 1].item())  # Probabilities for class 1 (binary case)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    ## ✅ **Confusion Matrix Plot**\n",
    "    ### Your code starts\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(6), yticklabels=range(6))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    ## ✅ **Classification Report**\n",
    "    print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    ## ✅ **ROC Curve & AUC Score**\n",
    "    if len(set(all_labels)) == 2:  # Only compute if binary classification\n",
    "        auc_score = roc_auc_score(all_labels, all_probs)\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
    "        plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "    return all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216381c3-798a-4eea-98e4-2708d1ae7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions_and_plot(gcn_pyg, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ceeaaf-9ed9-4fb7-95a9-055342cd78be",
   "metadata": {},
   "source": [
    "# Key findings and observations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
