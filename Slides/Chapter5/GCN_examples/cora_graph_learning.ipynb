{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Graph Learning with Cora Dataset**\n",
    "This notebook demonstrates **node classification, edge classification, and graph classification** using the **Cora dataset**, a well-known citation network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load the Cora Dataset** ğŸ“‚\n",
    "The **Cora dataset** consists of scientific papers categorized into different subjects. Papers are nodes, and citations between papers form edges.\n",
    "- **Nodes** represent research papers.\n",
    "- **Edges** represent citations between papers.\n",
    "- **Node features** are bag-of-words representations.\n",
    "- **Node labels** indicate the paper category (7 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /work/users/s/h/shuaishu/.conda/py10/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /work/users/s/h/shuaishu/.conda/py10/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /work/users/s/h/shuaishu/.conda/py10/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /work/users/s/h/shuaishu/.conda/py10/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /work/users/s/h/shuaishu/.conda/py10/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "Number of Nodes: 2708\n",
      "Number of Edges: 10556\n",
      "Node Feature Dimension: 1433\n",
      "Number of Classes: 7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Load the Cora dataset\n",
    "path = osp.join(os.getcwd(), 'data', 'Cora')\n",
    "dataset = Planetoid(path, 'Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "print(f'Dataset: {dataset}')\n",
    "print(f'Number of Nodes: {data.num_nodes}')\n",
    "print(f'Number of Edges: {data.num_edges}')\n",
    "print(f'Node Feature Dimension: {data.num_node_features}')\n",
    "print(f'Number of Classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Node Classification with Graph Convolutional Networks (GCN)** ğŸŸ¢\n",
    "**Goal**: Predict the label of a node using a GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.9454\n",
      "Epoch 20, Loss: 1.6305\n",
      "Epoch 40, Loss: 1.1211\n",
      "Epoch 60, Loss: 0.7123\n",
      "Epoch 80, Loss: 0.5006\n",
      "Epoch 100, Loss: 0.3905\n",
      "Epoch 120, Loss: 0.3252\n",
      "Epoch 140, Loss: 0.2822\n",
      "Epoch 160, Loss: 0.2519\n",
      "Epoch 180, Loss: 0.2293\n",
      "Node Classification Accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"Return the learned node embeddings.\"\"\"\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)  # Final node embeddings\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.encode(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# Train the GCN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(dataset.num_features, 16, dataset.num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "accuracy = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Node Classification Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Edge Classification (Link Prediction)** ğŸ”—\n",
    "**Goal**: Predict whether an edge (citation) exists between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Classification Accuracy: 0.7474\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "# Generate positive and negative edges\n",
    "pos_edge_index = data.edge_index\n",
    "neg_edge_index = negative_sampling(pos_edge_index, num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "# Train a model using edge features\n",
    "def edge_predictor(z, edge_index):\n",
    "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "pos_pred = edge_predictor(z, pos_edge_index)\n",
    "neg_pred = edge_predictor(z, neg_edge_index)\n",
    "\n",
    "edge_acc = ((pos_pred > 0).sum() + (neg_pred < 0).sum()) / (pos_pred.size(0) + neg_pred.size(0))\n",
    "print(f'Edge Classification Accuracy: {edge_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Graph Classification** ğŸ“Š\n",
    "**Goal**: Predict the category of a graph.\n",
    "Since Cora is a single graph, we typically use datasets with multiple graphs. However, we can create synthetic subgraphs from Cora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphClassifier(\n",
      "  (conv1): GCNConv(1433, 16)\n",
      "  (conv2): GCNConv(16, 7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "model = GraphClassifier(dataset.num_features, 16, dataset.num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
