{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Embedding Techniques in Python\n",
    "This notebook introduces different graph embedding methods and demonstrates their implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Node Embedding Methods\n",
    "Node embedding techniques aim to represent each node in a graph as a low-dimensional vector while preserving the structural and semantic relationships between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Encoder-Decoder for Node Embedding\n",
    "Autoencoders can be used to learn node embeddings by reconstructing the adjacency matrix or other graph structures.\n",
    "\n",
    "### **Graph Autoencoder (GAE) Objective Function:**\n",
    "$$ \\mathcal{L} = \\sum_{(i,j) \\in E} || A_{ij} - \\hat{A}_{ij} ||^2 $$\n",
    "- $ A $ is the adjacency matrix.\n",
    "- $ \\hat{A} $ is the reconstructed adjacency matrix.\n",
    "- The loss function minimizes the reconstruction error, ensuring embeddings capture the graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Example Run for Graph Autoencoder (GAE)**\n",
    "Now, let's apply our **Graph Autoencoder (GAE)** to learn node embeddings and reconstruct the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2371\n",
      "Epoch 20, Loss: 0.0055\n",
      "Epoch 40, Loss: 0.0001\n",
      "Epoch 60, Loss: 0.0000\n",
      "Epoch 80, Loss: 0.0000\n",
      "Epoch 100, Loss: 0.0000\n",
      "Epoch 120, Loss: 0.0000\n",
      "Epoch 140, Loss: 0.0000\n",
      "Epoch 160, Loss: 0.0000\n",
      "Epoch 180, Loss: 0.0000\n",
      "Node Embeddings Shape: torch.Size([34, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Define Graph Autoencoder (GAE)\n",
    "class GraphAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GCNConv(in_channels, hidden_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        return self.encoder(x, edge_index).relu()\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return torch.sigmoid(torch.sum(z[edge_index[0]] * z[edge_index[1]], dim=1))\n",
    "\n",
    "# Generate a sample graph\n",
    "G = nx.karate_club_graph()\n",
    "data = from_networkx(G)\n",
    "data.x = torch.eye(data.num_nodes)  # Use identity matrix as node features\n",
    "\n",
    "# Instantiate and train GAE\n",
    "model = GraphAutoencoder(in_channels=data.x.size(1), hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    loss = F.mse_loss(model.decode(z, data.edge_index), torch.ones(data.edge_index.size(1)))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "# Generate node embeddings\n",
    "model.eval()\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "print('Node Embeddings Shape:', z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Explanation of the Example Run**\n",
    "- We generate a **Karate Club Graph** (a well-known social network dataset).\n",
    "- We use an **identity matrix** as initial node features.\n",
    "- The **Graph Autoencoder (GAE)** learns embeddings by reconstructing the adjacency matrix.\n",
    "- The model is trained for **200 epochs** using Mean Squared Error (MSE) loss.\n",
    "- The **node embeddings** are extracted from the encoder after training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DeepWalk for Node Embedding\n",
    "DeepWalk generates random walks from each node and uses **Skip-gram (Word2Vec)** to learn node embeddings.\n",
    "\n",
    "### **DeepWalk Learning Objective:**\n",
    "$$ \\max \\sum_{v \\in V} \\sum_{u \\in N(v)} \\log P(u | v) $$\n",
    "- $ V $ is the set of nodes.\n",
    "- $ N(v) $ represents the context nodes obtained via random walks.\n",
    "- The probability $ P(u | v) $ is modeled using Skip-gram with negative sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: node2vec in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: networkx in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (3.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from node2vec) (4.66.6)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from node2vec) (4.3.3)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from node2vec) (1.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from node2vec) (1.25.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.1.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.10.1)\n",
      "Requirement already satisfied: wrapt in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.14.1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e95e4d6b24c9bbd408ddf75a00c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [00:00<00:00, 235.05it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [00:00<00:00, 245.38it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00, 248.57it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03371138  0.00471057  0.13197999  0.00064104 -0.09922037 -0.18864591\n",
      "  0.14211093 -0.04652401 -0.14178273  0.02769512  0.27235723 -0.05567688\n",
      " -0.08297646 -0.07268335  0.09086467 -0.0256397  -0.04040011  0.05774299\n",
      " -0.10838906  0.06713866  0.22494091  0.14894608  0.05475391  0.15392075\n",
      " -0.12386379  0.11761998 -0.14566028  0.16910063  0.06333711 -0.06941671\n",
      " -0.32792237 -0.03276331  0.05102498 -0.15237664 -0.06230216 -0.0258521\n",
      "  0.22699015  0.02365667  0.21208745  0.00715821 -0.02499608  0.16354631\n",
      " -0.07037735 -0.07002616 -0.01117198  0.15262796 -0.01470388 -0.12951931\n",
      "  0.02840152  0.03755466  0.15808448  0.02348655  0.16327459  0.04995153\n",
      "  0.05497856  0.10872374  0.14379376 -0.09098054 -0.14609477  0.04737015\n",
      "  0.12490214 -0.15646265  0.00324802  0.05044365  0.05020976 -0.1353709\n",
      "  0.12380543  0.06324374  0.0078472  -0.08213446  0.12353051 -0.01871051\n",
      " -0.19025104 -0.04672351 -0.02414738 -0.03031775 -0.05788708 -0.06149279\n",
      "  0.05448417  0.22005065  0.11390583 -0.12496471  0.07181402  0.25308564\n",
      "  0.0170301   0.11607575  0.08658431 -0.12858608  0.16587493  0.07811581\n",
      " -0.11442102  0.0023254   0.00402303  0.12419109  0.17364994 -0.03527287\n",
      " -0.2656856  -0.22752154  0.01531804 -0.09585924 -0.27180964  0.03792065\n",
      "  0.17020342  0.08713926  0.01611973 -0.0515087   0.24399406 -0.15120181\n",
      " -0.0135006  -0.21771525  0.11990559 -0.06820967  0.00114377  0.01339357\n",
      "  0.1189417  -0.06096319  0.05683765  0.20782687  0.05143354  0.06749961\n",
      " -0.03752906 -0.01695702 -0.00537678  0.0853768  -0.10257819 -0.2503934\n",
      " -0.13694537 -0.10107094]\n"
     ]
    }
   ],
   "source": [
    "!pip install node2vec networkx\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Create a sample graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Train DeepWalk (using Node2Vec with p=1, q=1)\n",
    "node2vec = Node2Vec(G, dimensions=128, walk_length=40, num_walks=10, workers=4, p=1, q=1)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Get embedding of a node\n",
    "print(model.wv['0'])  # Example node embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Node2Vec for Node Embedding\n",
    "Node2Vec extends DeepWalk by introducing hyperparameters **p** and **q** to control random walk behavior.\n",
    "\n",
    "### **Node2Vec Transition Probability:**\n",
    "$$ P(v_i | v) = \\frac{w_{v v_i}}{Z} $$\n",
    "where:\n",
    "- $ w_{v v_i} $ is the weight of the edge between nodes $ v $ and $ v_i $.\n",
    "- $ Z $ is a normalization factor.\n",
    "\n",
    "The hyperparameters **p** and **q** define the walk strategy:\n",
    "- **p > 1**: Biased towards depth-first search (DFS) (captures structural similarity).\n",
    "- **q > 1**: Biased towards breadth-first search (BFS) (captures neighborhood similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be4029c5ab24abcbe8a6ead633e6157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1202903  -0.12322044  0.01186979 -0.15394455 -0.02900799 -0.1470373\n",
      " -0.11592245  0.04669889  0.01383069  0.06194183  0.34580207  0.102961\n",
      " -0.0597943  -0.10464931 -0.03758498 -0.12749052 -0.11810691  0.07493912\n",
      " -0.191813   -0.04454722  0.03773009 -0.08224007  0.09282345  0.09029263\n",
      " -0.08777487  0.13681558 -0.10452212  0.03598142  0.12324533 -0.0466882\n",
      " -0.3003342  -0.02999849 -0.06051234 -0.05260294  0.09246498  0.15638356\n",
      "  0.06814784 -0.09943837  0.20739974  0.05369433  0.04821846  0.14943299\n",
      " -0.07356099 -0.1598666  -0.07103743 -0.03823644 -0.02144143 -0.16925715\n",
      "  0.16066977 -0.10602353  0.26623416 -0.068403    0.17112988  0.11798132\n",
      "  0.00299158  0.12068678  0.05099092 -0.05239482 -0.06737599  0.1251624\n",
      "  0.12514053 -0.11338504 -0.00627189  0.13145149  0.02280507  0.07204564\n",
      "  0.1771723   0.20161648 -0.06503736 -0.16277233  0.07037327 -0.28126395\n",
      " -0.09674021 -0.16563804  0.01831471 -0.1867492  -0.05197934 -0.14526072\n",
      "  0.14737658  0.24008416  0.07780101 -0.2564623   0.15008757  0.30919892\n",
      "  0.05584759  0.0444994   0.07037252  0.00380406  0.12984496  0.01106359\n",
      "  0.03007993  0.09797928  0.0975088   0.12436501  0.13698237 -0.12385396\n",
      " -0.2330413  -0.2686815   0.11229268 -0.21434177 -0.22514167  0.04961729\n",
      "  0.01308798  0.09011139  0.10663    -0.03529624  0.11609515 -0.23169935\n",
      "  0.07021023 -0.2040628   0.15149543  0.05584906  0.11083483  0.07867398\n",
      "  0.16962543 -0.09504984 -0.06595234  0.10358848  0.18362342  0.02698815\n",
      " -0.11456718 -0.00228218  0.06043768  0.1328981  -0.16465424 -0.18359494\n",
      "  0.02977694 -0.2812295 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [00:00<00:00, 252.76it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:00<00:00, 248.96it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:00<00:00, 253.23it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [00:00<00:00, 138.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train Node2Vec with custom parameters\n",
    "node2vec = Node2Vec(G, dimensions=128, walk_length=40, num_walks=10, workers=4, p=0.5, q=2)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Get embedding of a node\n",
    "print(model.wv['1'])  # Example node embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of Node Embedding Methods**\n",
    "- **Graph Autoencoder (GAE)**: Learns node embeddings by reconstructing the adjacency matrix.\n",
    "- **DeepWalk**: Uses random walks + Word2Vec for unsupervised learning.\n",
    "- **Node2Vec**: Extends DeepWalk with flexible random walk strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graph Embedding - Whole Graph Representation\n",
    "In this section, we will explore techniques for embedding entire graphs rather than individual nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Convolutional Networks (GCN) + Global Pooling\n",
    "Graph Convolutional Networks (GCN) learn node embeddings using graph convolutions. To embed an **entire graph**, we aggregate node embeddings using **global pooling**.\n",
    "\n",
    "### **GCN Update Rule:**\n",
    "$$ H^{(l+1)} = \\sigma( \\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} H^{(l)} W^{(l)} ) $$\n",
    "- $ \\tilde{A} $ is the adjacency matrix with self-loops.\n",
    "- $ \\tilde{D} $ is the degree matrix.\n",
    "- $ W^{(l)} $ is the learnable weight matrix.\n",
    "- $ \\sigma $ is an activation function (e.g., ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([28, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load a dataset of graphs\n",
    "dataset = TUDataset(root='data', name='MUTAG')\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class GraphEmbeddingGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphEmbeddingGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return global_mean_pool(x, batch)  # Pooling for graph embedding\n",
    "\n",
    "# Example training loop\n",
    "model = GraphEmbeddingGNN(dataset.num_node_features, 64, 32)\n",
    "for batch in loader:\n",
    "    embeddings = model(batch)\n",
    "    print(embeddings.shape)  # (batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph2Vec\n",
    "Graph2Vec is inspired by **Doc2Vec** and learns graph embeddings using the Weisfeiler-Lehman (WL) algorithm to generate graph substructure representations.\n",
    "\n",
    "### **Graph2Vec Objective Function:**\n",
    "$$ \\max \\sum_{G \\in D} \\sum_{h \\in H(G)} \\log P(h | G) $$\n",
    "where:\n",
    "- $ G $ is a graph.\n",
    "- $ H(G) $ is the set of substructures in $ G $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting karateclub\n",
      "  Downloading karateclub-1.3.3.tar.gz (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: networkx in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (3.4.2)\n",
      "Collecting numpy<1.23.0\n",
      "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting decorator==4.4.2\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: tqdm in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from karateclub) (4.66.6)\n",
      "Collecting python-louvain\n",
      "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from karateclub) (1.2.2)\n",
      "Requirement already satisfied: scipy in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from karateclub) (1.10.1)\n",
      "Collecting pygsp\n",
      "  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gensim>=4.0.0 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from karateclub) (4.3.3)\n",
      "Collecting pandas<=1.3.5\n",
      "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from karateclub) (1.16.0)\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from gensim>=4.0.0->karateclub) (7.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from pandas<=1.3.5->karateclub) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from pandas<=1.3.5->karateclub) (2.8.2)\n",
      "Collecting Levenshtein==0.26.1\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.9.0\n",
      "  Downloading rapidfuzz-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from scikit-learn->karateclub) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /nas/longleaf/home/shuaishu/.local/lib/python3.10/site-packages (from scikit-learn->karateclub) (1.4.2)\n",
      "Requirement already satisfied: wrapt in /nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim>=4.0.0->karateclub) (1.14.1)\n",
      "Building wheels for collected packages: karateclub, python-louvain\n",
      "  Building wheel for karateclub (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for karateclub: filename=karateclub-1.3.3-py3-none-any.whl size=101987 sha256=c482faf274e620e972692151c75b6e930737d0e2a4c2b2cdebed4a3ae1aad6a6\n",
      "  Stored in directory: /work/users/s/h/shuaishu/.cache/pip/wheels/23/01/a6/c89f9adc6e82860df72a686f489bc4b77aad81a5465b64a3d9\n",
      "  Building wheel for python-louvain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9389 sha256=8e9cceef36cb033835bf0e5ecdff11ef2d3287fcebad443aa414bca847df9719\n",
      "  Stored in directory: /work/users/s/h/shuaishu/.cache/pip/wheels/e0/2c/33/8b5604f69c4a6ed10fb867d51173c03f666920c7c8bbcedbaa\n",
      "Successfully built karateclub python-louvain\n",
      "Installing collected packages: rapidfuzz, numpy, networkx, decorator, python-louvain, pandas, Levenshtein, python-Levenshtein, pygsp, karateclub\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.18.0 requires protobuf!=4.24.0,>=3.19.6, which is not installed.\n",
      "nflows 0.14 requires torch, which is not installed.\n",
      "node2vec 0.5.0 requires networkx<4.0.0,>=3.1.0, but you have networkx 2.6.3 which is incompatible.\n",
      "node2vec 0.5.0 requires numpy<2.0.0,>=1.24.0, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Levenshtein-0.26.1 decorator-4.4.2 karateclub-1.3.3 networkx-2.6.3 numpy-1.22.4 pandas-1.3.5 pygsp-0.5.1 python-Levenshtein-0.26.1 python-louvain-0.16 rapidfuzz-3.12.1\n",
      "(3, 128)\n"
     ]
    }
   ],
   "source": [
    "!pip install karateclub networkx\n",
    "from karateclub import Graph2Vec\n",
    "import networkx as nx\n",
    "\n",
    "# Create example graphs\n",
    "G1 = nx.erdos_renyi_graph(20, 0.2)\n",
    "G2 = nx.barabasi_albert_graph(20, 2)\n",
    "G3 = nx.watts_strogatz_graph(20, 4, 0.1)\n",
    "graphs = [G1, G2, G3]\n",
    "\n",
    "# Train Graph2Vec\n",
    "graph2vec = Graph2Vec(dimensions=128, wl_iterations=2, min_count=1)\n",
    "graph2vec.fit(graphs)\n",
    "\n",
    "# Get graph embeddings\n",
    "graph_embeddings = graph2vec.get_embedding()\n",
    "print(graph_embeddings.shape)  # (num_graphs, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DiffPool (Hierarchical Graph Pooling)\n",
    "DiffPool is a hierarchical graph embedding approach where node embeddings are aggregated in a differentiable way to create coarser representations of the graph.\n",
    "\n",
    "### **DiffPool Forward Pass:**\n",
    "$$ Z = \\text{softmax}(S) X $$\n",
    "- $ S $ is the learned assignment matrix.\n",
    "- $ X $ is the node feature matrix.\n",
    "- $ Z $ is the pooled representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled X shape: torch.Size([1, 3, 16])\n",
      "Pooled Adjacency Matrix shape: torch.Size([1, 3, 3])\n",
      "Link Loss: 0.031235093250870705, Entropy Loss: 1.0217900276184082\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "\n",
    "class DiffPoolNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_clusters):\n",
    "        super(DiffPoolNet, self).__init__()\n",
    "        self.gcn1 = DenseGCNConv(in_channels, hidden_channels)\n",
    "        self.gcn2 = DenseGCNConv(hidden_channels, num_clusters)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gcn1(x, adj).relu()\n",
    "        s = self.gcn2(x, adj)\n",
    "        x, adj, link_loss, ent_loss = dense_diff_pool(x, adj, s)  # Unpack all values\n",
    "        return x, adj, link_loss, ent_loss  # Return all values\n",
    "\n",
    "# Example usage\n",
    "num_nodes, num_features, num_clusters = 10, 5, 3\n",
    "x = torch.rand((num_nodes, num_features))\n",
    "adj = torch.rand((num_nodes, num_nodes))\n",
    "\n",
    "model = DiffPoolNet(num_features, 16, num_clusters)\n",
    "pooled_x, pooled_adj, link_loss, ent_loss = model(x, adj)  # Correct unpacking\n",
    "\n",
    "print(f\"Pooled X shape: {pooled_x.shape}\")\n",
    "print(f\"Pooled Adjacency Matrix shape: {pooled_adj.shape}\")\n",
    "print(f\"Link Loss: {link_loss.item()}, Entropy Loss: {ent_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of Graph Embedding Methods**\n",
    "- **GCN + Pooling**: Uses Graph Convolutional Networks with global mean pooling for whole-graph embedding.\n",
    "- **Graph2Vec**: Learns graph embeddings using Weisfeiler-Lehman subtree features and Word2Vec.\n",
    "- **DiffPool**: A hierarchical pooling method for learning coarser graph representations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
