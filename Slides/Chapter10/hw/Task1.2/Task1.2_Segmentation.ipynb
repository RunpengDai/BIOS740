{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1.2: Running nnU-Net\n",
    "\n",
    "As seen in last task, the vanilla U-Net achives a performance that is not that bad. However, there is always room for more improvement. \n",
    "\n",
    "In this task, we will use the same dataset, ACDC, as in the previous one. There are many popular variants of the vanilla U-Net, one of which is the nnU-Net. nnU-Net (No New U-Net) is a self-configuring deep learning framework specifically designed for medical image segmentation tasks. It was introduced as a baseline model that autonomously adjusts its architecture, preprocessing, and training pipeline based on the characteristics of a given dataset, making it highly adaptable across different segmentation tasks without requiring manual tuning. Key features of nnUNet include:\n",
    "\n",
    "+ Out-of-the-box Performance: It automatically configures the model to achieve state-of-the-art performance on various datasets without extensive user intervention.\n",
    "+ Data-Driven Configurations: It customizes aspects like network architecture, patch size, and batch size depending on the size and properties of the input data.\n",
    "+ Cross-dataset Applicability: nnUNet works well across different datasets and imaging modalities, like MRI, CT, and X-rays.\n",
    "+ 3D and 2D Models: It supports both 2D and 3D U-Net models, adapting based on dataset dimensionality.\n",
    "+ Robust Preprocessing: The framework includes built-in data augmentation and normalization techniques to enhance performance and generalization.\n",
    "\n",
    "<img src=\"../img/nnU-Net.png\" width=\"800\" height=\"600\">\n",
    "\n",
    "For details of nn-UNet, please refer to the following paper. \n",
    "\n",
    "> Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring \n",
    "method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
    "\n",
    "You need to run the pipeline on ACDC dataset according to the documentation as described in https://github.com/MIC-DKFZ/nnUNet/tree/master/documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install nn-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "pip install nnunetv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environmental Variables\n",
    "\n",
    "nnU-Net requires the following environmental variables to be set: `nnUNet_raw`, `nnUNet_preprocessed`, `nnUNet_results`.\n",
    "\n",
    "Here we define these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# Define some variables\n",
    "%env nnUNet_raw=../data/nnUNet/nnUNet_raw\n",
    "%env nnUNet_preprocessed=../data/nnUNet/nnUNet_preprocessed\n",
    "%env nnUNet_results=../data/nnUNet/nnUNet_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the dataset conversion script, we need to make a bit modification to the downloaded ACDC dataset. In other words, we need to make sure the target path contains extracted 'training' and 'testing' sub-folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# todo: Enter the same path in previous task.\n",
    "# Hint: The path_ACDC_all and path_ACDC_separate should be two different folders, and the first folder should have been created in task1.1\n",
    "path_ACDC_all = None\n",
    "path_ACDC_separate = None\n",
    "\n",
    "if os.path.exists(path_ACDC_separate):\n",
    "    shutil.rmtree(path_ACDC_separate)\n",
    "os.makedirs(path_ACDC_separate)\n",
    "\n",
    "training_path = os.path.join(path_ACDC_separate, \"training\")\n",
    "testing_path = os.path.join(path_ACDC_separate, \"testing\")\n",
    "os.makedirs(training_path)\n",
    "os.makedirs(testing_path)\n",
    "\n",
    "for folder in os.listdir(path_ACDC_all):\n",
    "    if folder.startswith(\"patient\"):\n",
    "        patient_name = folder\n",
    "        patient_id = int(patient_name.split(\"t\")[2])\n",
    "        if patient_id <= 100:\n",
    "            shutil.copytree(os.path.join(path_ACDC_all, folder), os.path.join(training_path, folder))\n",
    "        else:\n",
    "            shutil.copytree(os.path.join(path_ACDC_all, folder), os.path.join(testing_path, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a ready-to-use script that can be used to transform ACDC dataset to the desried format for nnU-Net. Please find the script and put it inside the `Task1.2` folder, renaming it as `dataset_conversion.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!python ./dataset_conversion.py -i $path_ACDC_separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the suffix of data in `imagesTr`? What does that represent? Could you think of a case that it needs to be changed?\n",
    "\n",
    "The suffix is `0000`, which means that there is only one modality (short-axis) in the dataset. If there are multiple modalities, the suffix should be changed to represent the modality so that multi-modality training can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the nnU-Net by default will train for 1000 epochs, please modify `self.num_epochs` to 200 in `<virtual env>/lib/<python>/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py` so that the training will not take a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset are prepared, you only need to finish the following steps to run nnU-Net on ACDC dataset.\n",
    "\n",
    "+ Preprocess the dataset\n",
    "+ Train the 2D model using the training set\n",
    "+ Determine the best configuration of possible model. The training progress can be tracked in `nnUNet_results` folder.\n",
    "+ Conduct Inference on the testing set, store the results in `labelsTs` folder.\n",
    "+ Apply post-processing on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 027 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!nnUNetv2_train 027 2d all --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!nnUNetv2_find_best_configuration 027 -c 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ACDC_testing_image = os.path.join(\"../data/nnUNet/nnUNet_raw/Dataset027_ACDC/\", \"imagesTs\")\n",
    "path_ACDC_testing_label = os.path.join(\"../data/nnUNet/nnUNet_raw/Dataset027_ACDC/\", \"labelsTs\")\n",
    "# post processsed\n",
    "path_ACDC_testing_label_pp = os.path.join(\"../data/nnUNet/nnUNet_raw/Dataset027_ACDC/\", \"labelsTs_PP\")\n",
    "os.makedirs(path_ACDC_testing_label, exist_ok=True)\n",
    "os.makedirs(path_ACDC_testing_label_pp, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!nnUNetv2_predict -d Dataset027_ACDC -i $path_ACDC_testing_image -o $path_ACDC_testing_label -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!nnUNetv2_apply_postprocessing -i $path_ACDC_testing_label -o $path_ACDC_testing_label_pp -pp_pkl_file $nnUNet_results/Dataset027_ACDC/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json $nnUNet_results/Dataset027_ACDC/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `torchmetrics` to calculate the Dice and Jaccard index as previous task for the last 30 patients after post-processing (121~150). Report the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import torch\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from utils.Task1_utils import load_config\n",
    "\n",
    "config = load_config(\"../config/Task1.1_config.yaml\")\n",
    "NUM_CLASSES = config[\"dataset\"][\"number_classes\"]\n",
    "metrics = torchmetrics.MetricCollection(\n",
    "    [\n",
    "        # todo Evaluate Dice and Jaccard Index\n",
    "        None,\n",
    "        None\n",
    "    ],\n",
    "    prefix=\"metrics/\",\n",
    ")\n",
    "test_metrics = metrics.clone(prefix=\"test_metrics/\").to(device)\n",
    "test_evaluator = test_metrics.clone().to(device)\n",
    "\n",
    "for file in tqdm(os.listdir(path_ACDC_testing_label_pp)):\n",
    "    if file.startswith(\"patient\"):\n",
    "        patient_name = file.split(\".\")[0]\n",
    "        patient_id = int(patient_name.split(\"_\")[0].split(\"t\")[2])\n",
    "        frame = patient_name.split(\"_\")[1].split(\"e\")[1]\n",
    "        if patient_id > 120:\n",
    "            # image_data = nib.load(os.path.join(path_ACDC_testing_image, f\"{patient_name}_0000.nii.gz\")).get_fdata()\n",
    "            mask_data = nib.load(\n",
    "                os.path.join(\n",
    "                    path_ACDC_all,\n",
    "                    f\"patient{patient_id}\",\n",
    "                    f\"patient{patient_id}_frame{frame}_gt.nii.gz\",\n",
    "                )\n",
    "            ).get_fdata()\n",
    "            pred_data = nib.load(\n",
    "                os.path.join(path_ACDC_testing_label_pp, f\"{patient_name}.nii.gz\")\n",
    "            ).get_fdata()\n",
    "            for s in range(mask_data.shape[2]):\n",
    "                preds_ = torch.from_numpy(pred_data[:, :, s].astype(np.uint8))\n",
    "                masks_ = torch.from_numpy(mask_data[:, :, s].astype(np.uint8))\n",
    "                test_evaluator.update(preds_, masks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_evaluator.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please report the Dice and Jaccard Index score for nnUNet. How does it compare to the vanilla U-Net?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
