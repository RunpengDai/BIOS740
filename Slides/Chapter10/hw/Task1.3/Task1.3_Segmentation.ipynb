{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1.3: Exploring Segment Anything (SA)\n",
    "\n",
    "In this last task of segmentation, we will explore how to make use of some state-of-the art segmentation models to deal with medical images. \n",
    "\n",
    "Vision Transformer (ViT) model was introduced to alleviate the deficiency of CNNs in capturing the long-range semantic dependencies. One particular example of ViT is  the Segment Anything (SA) project. The visualized plots generated in task 1.1 motivates the idea that including some kind of \"guidance\" for the model to accurately segment the desired area. Such thought can be realized through **prompt**. The SA model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.\n",
    "\n",
    "> Kirillov, Alexander, et al. \"Segment anything.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `segment_anything` folder is provided for you, which can also be downloaded using the [link](https://github.com/facebookresearch/segment-anything). \n",
    "\n",
    "We will use the ViT-B SAM model that is the smallest in size of parameters. Please download the corresponding checkpoint, which is named as `vit_b` in the Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.Task1_utils import show_box, show_points, show_mask\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sam_checkpoint = \"model/sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let us visualize the second slice of ED phase of the first patient in ACDC dataset as the first slice doesn't contain the annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "\n",
    "# todo: Enter the same path in previous task.\n",
    "path_ACDC_all = None\n",
    "\n",
    "nim_image = os.path.join(path_ACDC_all, \"patient001\", \"patient001_frame01.nii.gz\")\n",
    "nim_mask = os.path.join(path_ACDC_all, \"patient001\", \"patient001_frame01_gt.nii.gz\")\n",
    "image = nib.load(nim_image).get_fdata()[:, :, 1]\n",
    "# normalize and resize\n",
    "image = (image - image.min()) / (image.max() - image.min()) * 255\n",
    "image = image.astype(np.uint8)\n",
    "image = cv2.resize(image, (512, 512))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "mask = nib.load(nim_mask).get_fdata()[:, :, 1]\n",
    "mask = np.where(mask == 0, np.nan, mask)\n",
    "mask = cv2.resize(mask, (512, 512))\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.imshow(mask, cmap=\"jet\", alpha=0.5)\n",
    "\n",
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your job is to segment the left ventricle, myocardium as well as right ventricles using the SA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting Left Ventricle\n",
    "\n",
    "As illustrated in the plot, the left ventricle has an approximate shape of a circle. Please draw a bounding box as the prompt supplied for the SA model.\n",
    "\n",
    "**Note: It is almost inevitable to have the myocardium in the mask if we only draw a bounding box!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: Give one working bounding box\n",
    "input_box = None\n",
    "\n",
    "masks, _, _ = predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=input_box,\n",
    "                    multimask_output=False,\n",
    "                )\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "show_box(input_box, plt.gca())\n",
    "show_mask(masks[0], plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting Right Ventricle\n",
    "\n",
    "You may have failed to exclude the myocardium in the left ventricle segmentation. Fortunately, SA model allows us to choose points to exclude from the mask. Please draw a bounding box to segment the myocardium while also providing exclusion points so that left ventricle is not inclued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: Give one working bounding box and one set of exclusion points\n",
    "input_box = None\n",
    "input_point = None\n",
    "input_label = None\n",
    "\n",
    "masks, _, _ = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=False,\n",
    "                    box=input_box,\n",
    "                )\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "show_box(input_box, plt.gca())\n",
    "show_points(input_point, input_label,plt.gca())\n",
    "show_mask(masks[0], plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Right ventricle tends to have significant shape variation. For such problem, can you think of another approach except for changing the architecture of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to use the **boundary loss** instead of pixel-level or region-level loss. You can refer to the following review paper for more information.\n",
    "\n",
    "> Azad, R., Heidary, M., Yilmaz, K., HÃ¼ttemann, M., Karimijafarbigloo, S., Wu, Y., Schmeink, A., & Merhof, D. (2023). Loss Functions in the Era of Semantic Segmentation: A Survey and Outlook (No. arXiv:2312.05391). arXiv. http://arxiv.org/abs/2312.05391"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
