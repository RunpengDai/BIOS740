{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67153546-cc0d-4a18-882f-a44ab7d622e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import vgg16\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_metric\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c14d0-93b2-4345-9af1-03f92e73ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# TODO: Implement the T1T2Dataset class:\n",
    "# 1. Initialize the dataset by loading the T1 and T2 image paths.\n",
    "# 2. Implement the __len__ method to return the number of samples.\n",
    "# 3. Implement the __getitem__ method to load and transform images.\n",
    "##########################################################\n",
    "\n",
    "class T1T2Dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        # Step 1: Load and sort image paths\n",
    "        # Replace \"pass\" with your code\n",
    "        #pass\n",
    "        self.t1_images = #pass\n",
    "        self.t2_images = #pass\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Step 2: Return the number of samples\n",
    "        #pass\n",
    "        return #pass\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Step 3: Load images and apply transformations\n",
    "        #pass\n",
    "        t1_image = #pass\n",
    "        t2_image = #pass\n",
    "\n",
    "        if self.transform:\n",
    "            t1_image = #pass\n",
    "            t2_image = #pass\n",
    "\n",
    "        return t1_image, t2_image\n",
    "\n",
    "#############################################################\n",
    "# END OF YOUR CODE\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf55a6-0503-4be1-a297-525830f2b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Create Dataset and DataLoaders\n",
    "dataset = T1T2Dataset(\n",
    "    data_dir='../img/pair_slices/',\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7563a1-b942-4c34-a655-3fbfbf5f8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8f5aa-86b3-4956-98a5-2c824d981603",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# TODO: Implement the UNetGenerator class:\n",
    "# 1. Define the encoder (downsampling) layers.\n",
    "# 2. Define the decoder (upsampling) layers with skip connections.\n",
    "# 3. Implement the forward method to connect the layers.\n",
    "##########################################################\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=1, num_filters=64):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        # Step 1: Define the encoder layers\n",
    "        #pass\n",
    "        self.down1 = #pass\n",
    "        self.down2 = #pass\n",
    "        self.down3 = #pass\n",
    "        self.down4 = #pass\n",
    "        self.down5 = #pass\n",
    "        self.down6 = #pass\n",
    "        self.down7 = #pass\n",
    "        self.down8 = #pass\n",
    "\n",
    "        # Step 2: Define the decoder layers\n",
    "        #pass\n",
    "        self.up1 = #pass\n",
    "        self.up2 = #pass\n",
    "        self.up3 = #pass\n",
    "        self.up4 = #pass\n",
    "        self.up5 = #pass\n",
    "        self.up6 = #pass\n",
    "        self.up7 = #pass\n",
    "        self.up8 = #pass\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels, normalize=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def deconv_block(self, in_channels, out_channels, dropout=0.0):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 3: Implement the forward pass with skip connections\n",
    "        #pass\n",
    "        d1 = #pass\n",
    "        d2 = #pass\n",
    "        d3 = #pass\n",
    "        d4 = #pass\n",
    "        d5 = #pass\n",
    "        d6 = #pass\n",
    "        d7 = #pass\n",
    "        d8 = #pass\n",
    "\n",
    "        u1 = #pass\n",
    "        u2 = #pass\n",
    "        u3 = #pass\n",
    "        u4 = #pass\n",
    "        u5 = #pass\n",
    "        u6 = #pass\n",
    "        u7 = #pass\n",
    "        u8 = #pass\n",
    "\n",
    "        return u8\n",
    "\n",
    "#############################################################\n",
    "# END OF YOUR CODE\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f66376-40d0-4be2-b801-cabf7daebbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# TODO: Implement the Discriminator class:\n",
    "# 1. Define the convolutional layers of the discriminator.\n",
    "# 2. Implement the forward method.\n",
    "##########################################################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=2, num_filters=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Step 1: Define the convolutional layers\n",
    "        #pass\n",
    "        self.model = #pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 2: Implement the forward pass\n",
    "        #pass\n",
    "        return #pass\n",
    "\n",
    "#############################################################\n",
    "# END OF YOUR CODE\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c0536-eae3-4268-b00e-474fd7ac46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# TODO: Implement the Pix2PixModel class:\n",
    "# 1. Implement the training_step for both generator and discriminator.\n",
    "# 2. Implement the validation_step to compute evaluation metrics.\n",
    "##########################################################\n",
    "class Pix2PixModel(pl.LightningModule):\n",
    "    def __init__(self, lr=2e-4, beta1=0.5):\n",
    "        super(Pix2PixModel, self).__init__()\n",
    "        self.generator = UNetGenerator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.loss_gan = nn.BCELoss()\n",
    "        self.loss_l1 = nn.L1Loss()\n",
    "        # Load pre-trained VGG16 for perceptual loss\n",
    "        self.vgg = vgg16(pretrained=True).features[:16].eval()\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Enable manual optimization\n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "    def perceptual_loss(self, gen, target):\n",
    "        # gen and target are [batch_size, 1, H, W]\n",
    "        # Duplicate channels to convert to 3-channel images\n",
    "        gen_rgb = gen.repeat(1, 3, 1, 1)  # Now gen_rgb is [batch_size, 3, H, W]\n",
    "        target_rgb = target.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Normalize using ImageNet mean and std\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=gen.device).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=gen.device).view(1, 3, 1, 1)\n",
    "\n",
    "        gen_rgb = (gen_rgb - mean) / std\n",
    "        target_rgb = (target_rgb - mean) / std\n",
    "\n",
    "        gen_features = self.vgg(gen_rgb)\n",
    "        target_features = self.vgg(target_rgb)\n",
    "        return F.l1_loss(gen_features, target_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_g = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "        optimizer_d = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "        return [optimizer_g, optimizer_d]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Step 1: Implement the training step for generator and discriminator\n",
    "        real_A, real_B = batch  # real_A is T1, real_B is T2\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(real_B.size(0), 1, 30, 30).type_as(real_B)\n",
    "        fake = torch.zeros(real_B.size(0), 1, 30, 30).type_as(real_B)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        # Generate fake images\n",
    "        fake_B = #pass\n",
    "        # Discriminator's opinion on the generated images\n",
    "        pred_fake = #pass\n",
    "        # Calculate generator loss\n",
    "        loss_gan = #pass\n",
    "        # L1 loss\n",
    "        loss_l1 = #pass\n",
    "        # Perceptual loss\n",
    "        loss_perceptual = #pass\n",
    "        # Total loss\n",
    "        loss_G = loss_gan + 100 * loss_l1 + 10 * loss_perceptual\n",
    "\n",
    "        # Optimize generator\n",
    "        self.manual_backward(loss_G)\n",
    "        opt_g.step()\n",
    "        opt_g.zero_grad()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        # Real loss\n",
    "        pred_real = #pass\n",
    "        loss_real = #pass\n",
    "\n",
    "        # Fake loss\n",
    "        # Detach to avoid updating generator parameters\n",
    "        fake_B_detached = fake_B.detach()\n",
    "        pred_fake = #pass\n",
    "        loss_fake = #pass\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_D = (loss_real + loss_fake) * 0.5\n",
    "\n",
    "        # Optimize discriminator\n",
    "        self.manual_backward(loss_D)\n",
    "        opt_d.step()\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        # Logging losses\n",
    "        self.log('loss_G', loss_G, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        self.log('loss_D', loss_D, prog_bar=True, on_step=True, on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Step 2: Implement the validation step to compute PSNR and SSIM\n",
    "        real_A, real_B = batch\n",
    "        fake_B = self.generator(real_A)\n",
    "\n",
    "        # Denormalize images\n",
    "        real_B_denorm = real_B * 0.5 + 0.5\n",
    "        fake_B_denorm = fake_B * 0.5 + 0.5\n",
    "\n",
    "        real_B_np = real_B_denorm.cpu().numpy()\n",
    "        fake_B_np = fake_B_denorm.cpu().numpy()\n",
    "\n",
    "        batch_psnr = 0\n",
    "        batch_ssim = 0\n",
    "\n",
    "        for i in range(real_B_np.shape[0]):\n",
    "            real_img = #pass\n",
    "            fake_img = #pass\n",
    "\n",
    "            psnr_value = #pass\n",
    "            ssim_value = #pass\n",
    "\n",
    "            batch_psnr += psnr_value\n",
    "            batch_ssim += ssim_value\n",
    "\n",
    "        avg_psnr = #pass\n",
    "        avg_ssim = #pass\n",
    "\n",
    "        self.log('val_psnr', avg_psnr, prog_bar=True)\n",
    "        self.log('val_ssim', avg_ssim, prog_bar=True)\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            grid = make_grid(\n",
    "                torch.cat([real_A[:4], fake_B[:4], real_B[:4]], dim=0),\n",
    "                nrow=4, normalize=True\n",
    "            )\n",
    "            self.logger.experiment.add_image('val_images', grid, self.current_epoch)\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        real_A, real_B = batch\n",
    "        fake_B = self.generator(real_A)\n",
    "\n",
    "        # Denormalize images for metric computation\n",
    "        real_B_denorm = real_B * 0.5 + 0.5  # Convert from [-1,1] to [0,1]\n",
    "        fake_B_denorm = fake_B * 0.5 + 0.5\n",
    "\n",
    "        # Convert tensors to numpy arrays\n",
    "        real_B_np = real_B_denorm.cpu().numpy()\n",
    "        fake_B_np = fake_B_denorm.cpu().numpy()\n",
    "\n",
    "        # Initialize metric accumulators\n",
    "        batch_psnr = 0\n",
    "        batch_ssim = 0\n",
    "\n",
    "        for i in range(real_B_np.shape[0]):\n",
    "            real_img = real_B_np[i, 0] \n",
    "            fake_img = fake_B_np[i, 0]\n",
    "\n",
    "            # Compute PSNR and SSIM\n",
    "            psnr_value = psnr_metric(real_img, fake_img, data_range=1.0)\n",
    "            ssim_value = ssim_metric(real_img, fake_img, data_range=1.0)\n",
    "\n",
    "            batch_psnr += psnr_value\n",
    "            batch_ssim += ssim_value\n",
    "\n",
    "        # Average over batch\n",
    "        avg_psnr = batch_psnr / real_B_np.shape[0]\n",
    "        avg_ssim = batch_ssim / real_B_np.shape[0]\n",
    "\n",
    "        self.log('test_psnr', avg_psnr, prog_bar=True)\n",
    "        self.log('test_ssim', avg_ssim, prog_bar=True)\n",
    "\n",
    "        # Optionally log images\n",
    "        if batch_idx == 0:\n",
    "            grid = make_grid(\n",
    "                torch.cat([real_A[:4], fake_B[:4], real_B[:4]], dim=0),\n",
    "                nrow=4, normalize=True\n",
    "            )\n",
    "            self.logger.experiment.add_image('test_images', grid, self.current_epoch)\n",
    "#############################################################\n",
    "# END OF YOUR CODE\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148bdba-5cc8-42e7-b465-c39797ef7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model and Trainer\n",
    "model = Pix2PixModel()\n",
    "\n",
    "##########################################################\n",
    "# TODO: Set up the training process:\n",
    "# 1. Initialize the Trainer with appropriate parameters.\n",
    "# 2. Start the training process.\n",
    "##########################################################\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_psnr',\n",
    "    min_delta=0.00,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"GAN\")\n",
    "\n",
    "trainer = #pass\n",
    "\n",
    "# Train the Model\n",
    "trainer.fit('''pass''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa86fe3-32a7-4401-94d6-7b8d7fe7272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encountered error: ModuleNotFoundError: Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\n",
    "# Please make sure you have tensorboard and tensorboardX installed as listed in the requirements.txt \n",
    "# Please try:\n",
    "'''\n",
    "from lightning_utilities.core.imports import RequirementCache\n",
    "\n",
    "print(RequirementCache(\"tensorboard\"))\n",
    "print(RequirementCache(\"tensorboardx\"))\n",
    "'''\n",
    "# Try restarting session if \n",
    "'''\n",
    "Requirement 'tensorboard' met\n",
    "Requirement 'tensorboardx' met\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e44eec-b504-4cef-ab7c-86f251bd5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model training is done.')\n",
    "trainer.save_checkpoint(\"GAN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3135fc-f0ae-458f-94a1-25832b4cd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64781785-3c7c-4bee-ba3d-8a0029695706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, dataloader, num_images=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            real_A, real_B = batch\n",
    "            fake_B = model.generator(real_A)\n",
    "\n",
    "            # Denormalize images\n",
    "            real_A = real_A * 0.5 + 0.5\n",
    "            fake_B = fake_B * 0.5 + 0.5\n",
    "            real_B = real_B * 0.5 + 0.5\n",
    "\n",
    "            # Plot images\n",
    "            for i in range(min(num_images, real_A.size(0))):\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "                axs[0].imshow(real_A[i, 0].cpu(), cmap='gray')\n",
    "                axs[0].set_title('Input T1')\n",
    "                axs[1].imshow(fake_B[i, 0].cpu(), cmap='gray')\n",
    "                axs[1].set_title('Generated T2')\n",
    "                axs[2].imshow(real_B[i, 0].cpu(), cmap='gray')\n",
    "                axs[2].set_title('Ground Truth T2')\n",
    "                for ax in axs:\n",
    "                    ax.axis('off')\n",
    "                plt.show()\n",
    "            break  # Only visualize one batch\n",
    "\n",
    "# Visualize the results\n",
    "visualize_results(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd758e68-5bd3-48d5-82d8-950c6cb019e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
